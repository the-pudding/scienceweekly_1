{"title":"Science Weekly: The Hidden Face of Research","author":"Ilia Blinderman","header-title__top":"Contents lists available at <a href=”https://pudding.cool/>The Pudding</a>","header-title__middle":"The Pudding’s Science Weekly","header-title__bottom":"homepage: <a href=”https://pudding.cool”>www.pudding.cool</a>","intro":"Welcome to The Pudding’s Science Weekly. This is the first of 4 pieces devoted to exploring little-known scientific findings about science. Specifically, the unexpected or underappreciated aspects of how we do science, and its implications.","background":[{"type":"text","value":"Science, so the popular belief goes, involves <a href=”https://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants” target=_blank>standing on the shoulders of giants</a>: we run experiments, submit the results to a group of expert peers, and publishing the summary in a journal for others to refer to in their own studies. As researchers, we tend to see these results as trustworthy, and base our careers — our research interests, grant applications, and years of graduate school — on the contents of published results. But what happens when trust in science erodes? Psychology, my field of study for nearly a decade, is facing just such a <a href=”https://www.theatlantic.com/science/archive/2018/11/psychologys-replication-crisis-real/576223/”>crisis</a>. <a href=”https://www.youtube.com/watch?v=Ks-_Mh1QhMc”>Power poses</a>? <a href=”https://slate.com/technology/2016/01/amy-cuddys-power-pose-research-is-the-latest-example-of-scientific-overreach.html”>Highly questionable</a>. The popular conception of <a href=”https://www.thecut.com/2017/01/psychologys-racism-measuring-tool-isnt-up-to-the-job.html”>implicit bias</a>? Thoroughly <a href=”https://www.thecut.com/2017/01/psychologys-racism-measuring-tool-isnt-up-to-the-job.html”>suspect</a>. What to do to boost faith in unusual findings? One solution: give researchers access to the relevant raw data to analyze for themselves. Unfortunately, that’s easier said than done."}],"part-1":"In 2013, a group of researchers led by UBC’s Timothy Vine found that the <a href=”https://www.cell.com/current-biology/fulltext/S0960-9822(13)01400-0”>availability of research data declines rapidly with article age</a>. Say you’re a young researcher, and you’ve got a hunch that some highly-lauded study published two decades ago actually hinges on nothing but poor analysis and someone’s dreams of tenure; there’s a 90% likelihood that these data just <a href=”https://www.youtube.com/watch?v=xbBD7VIJ4cc&feature=youtu.be&t=67”>aren’t around</a> anymore. But what does that really mean, in concrete terms? How much of our work, as scientists, is the equivalent of an iceberg tip whose bottom melted away?","part-2":"When I was younger, I wanted to be an academic — I studied the link between our mental and physical states. Here’s a portion of my Master’s thesis, submitted the same year as paper you just saw. The whole thing rests on the literature review you see here, where I scoured the available evidence frame my hypothesis about the link between expectations of symptoms and their physical manifestation. Were I to seek the original data used in these studies, let’s see how likely I’d be to obtain it according to the probabilities in the paper we first discussed.","part-3":"I’ve color-coded each sentence that included a citation to past research. Dark passages are more likely to have data behind the studies; light ones are likely missing the raw data which led to the findings in the first place.","part-4":"Here’s how much of the paper disappears if we remove the studies that have a high probability of having inaccessible data. The vast majority of the evidence I’ve based two years of research on are likely to have, essentially, disappeared into the ether. So what’s the fix? Apart from heighetning researchers’ own awareness of this phenomenon, submitting raw, thoroughly anonymized data (when possible to do so ethically) to <a href=”https://collections.plos.org/10yr-datasets”>journals</a> should become routine, and go some ways towards restoring faith in scientific discovery.","part-5":"It’s important to note that the findings in the  <a href=”https://www.cell.com/current-biology/fulltext/S0960-9822(13)01400-0”>2013 paper we based this project on</a> pertain to biological data found in biology journals; the specific numbers may very well differ based on discipline. Additionally, the likelihoods displayed in this visualization should not be taken as an indicator than any specific study in a literature review lacks sufficient data-storage protocols, and should only be taken as a rough indicator of directional relationship between a citation’s age and its data’s availability. You may find the thesis cited in this project <a href=”http://digitool.library.mcgill.ca/R/-?func=dbin-jump-full&amp;current_base=GEN01&amp;object_id=117003”> here</a>."}